"""
EmotiSync æœåŠ¡å™¨ç«¯API
@description åŸºäºæ·±åº¦å­¦ä¹ çš„äººè„¸è¡¨æƒ…è¯†åˆ«æœåŠ¡
@author EmotiSync Team
@version 1.0.0
"""

from flask import Flask, request, jsonify
import base64
import cv2
import numpy as np
from ultralytics import YOLO
from flask_cors import CORS
import Config
import logging
import os
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ›å»ºFlaskåº”ç”¨å®ä¾‹
app = Flask(__name__)
CORS(app, 
     origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
     methods=["GET", "POST", "OPTIONS"],
     allow_headers=["Content-Type", "Authorization"])

# åº”ç”¨é…ç½®
app.config.update({
    'MAX_CONTENT_LENGTH': 16 * 1024 * 1024,  # 16MBæ–‡ä»¶å¤§å°é™åˆ¶
    'JSON_AS_ASCII': False,  # æ”¯æŒä¸­æ–‡JSONå“åº”
    'SECRET_KEY': 'emotisync_server_2024'
})

# æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    'face_detection_model': "model/yolov8n-face.pt",
    'expression_classification_model': "model/expression_cls.pt",
    'confidence_threshold': 0.5,
    'max_faces': 10
}

# å…¨å±€æ¨¡å‹å®ä¾‹
face_detector = None
expression_classifier = None

def initialize_models():
    """åˆå§‹åŒ–AIæ¨¡å‹"""
    global face_detector, expression_classifier
    
    try:
        logger.info("å¼€å§‹åŠ è½½AIæ¨¡å‹...")
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(MODEL_CONFIG['face_detection_model']):
            raise FileNotFoundError(f"äººè„¸æ£€æµ‹æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_CONFIG['face_detection_model']}")
        
        if not os.path.exists(MODEL_CONFIG['expression_classification_model']):
            raise FileNotFoundError(f"è¡¨æƒ…è¯†åˆ«æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_CONFIG['expression_classification_model']}")
        
        # åŠ è½½æ¨¡å‹
        face_detector = YOLO(MODEL_CONFIG['face_detection_model'])
        expression_classifier = YOLO(MODEL_CONFIG['expression_classification_model'])
        
        logger.info("AIæ¨¡å‹åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        raise RuntimeError(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")

def detect_faces_in_image(input_image):
    """
    åœ¨å›¾åƒä¸­æ£€æµ‹äººè„¸
    @param input_image: è¾“å…¥çš„å›¾åƒæ•°ç»„
    @return: (æ ‡æ³¨åçš„å›¾åƒ, äººè„¸å›¾åƒåˆ—è¡¨, äººè„¸ä½ç½®åˆ—è¡¨)
    """
    try:
        # å¤åˆ¶å›¾åƒé¿å…ä¿®æ”¹åŸå›¾
        processed_image = input_image.copy()
        
        # ä½¿ç”¨äººè„¸æ£€æµ‹æ¨¡å‹
        detection_results = face_detector(
            processed_image, 
            conf=MODEL_CONFIG['confidence_threshold'],
            verbose=False
        )
        
        face_crops = []
        face_positions = []
        
        # å¤„ç†æ£€æµ‹ç»“æœ
        if len(detection_results[0].boxes.data) > 0:
            face_boxes = detection_results[0].boxes.xyxy.tolist()
            
            # é™åˆ¶æœ€å¤§äººè„¸æ•°é‡
            if len(face_boxes) > MODEL_CONFIG['max_faces']:
                face_boxes = face_boxes[:MODEL_CONFIG['max_faces']]
                logger.warning(f"æ£€æµ‹åˆ°{len(face_boxes)}å¼ äººè„¸ï¼Œå·²é™åˆ¶ä¸º{MODEL_CONFIG['max_faces']}å¼ ")
            
            for box_coords in face_boxes:
                # è½¬æ¢åæ ‡ä¸ºæ•´æ•°
                x1, y1, x2, y2 = map(int, box_coords)
                face_positions.append([x1, y1, x2, y2])
                
                # æå–äººè„¸åŒºåŸŸ
                face_crop = processed_image[y1:y2, x1:x2]
                face_crops.append(face_crop)
                
                # åœ¨åŸå›¾ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
                cv2.rectangle(
                    processed_image, 
                    (x1, y1), (x2, y2), 
                    (46, 204, 113), 3  # ç»¿è‰²æ£€æµ‹æ¡†
                )
        
        logger.info(f"æˆåŠŸæ£€æµ‹åˆ° {len(face_crops)} å¼ äººè„¸")
        return processed_image, face_crops, face_positions
        
    except Exception as e:
        logger.error(f"äººè„¸æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {str(e)}")
        raise

def classify_facial_expression(face_image):
    """
    å¯¹äººè„¸å›¾åƒè¿›è¡Œè¡¨æƒ…åˆ†ç±»
    @param face_image: äººè„¸å›¾åƒ
    @return: (è¡¨æƒ…æ ‡ç­¾, ç½®ä¿¡åº¦)
    """
    try:
        # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
        gray_face = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
        # è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆæ¨¡å‹è¦æ±‚ï¼‰
        rgb_face = cv2.cvtColor(gray_face, cv2.COLOR_GRAY2RGB)
        
        # è¡¨æƒ…åˆ†ç±»
        classification_results = expression_classifier(rgb_face, verbose=False)
        probabilities = classification_results[0].probs.data.tolist()
        
        # è·å–æœ€é«˜æ¦‚ç‡çš„è¡¨æƒ…
        emotion_index = np.argmax(probabilities)
        emotion_label = Config.names[emotion_index]
        confidence_score = probabilities[emotion_index]
        
        return emotion_label, confidence_score
        
    except Exception as e:
        logger.error(f"è¡¨æƒ…åˆ†ç±»è¿‡ç¨‹å‡ºé”™: {str(e)}")
        raise

def process_image_data(base64_image):
    """
    å¤„ç†Base64å›¾åƒæ•°æ®
    @param base64_image: Base64æ ¼å¼çš„å›¾åƒå­—ç¬¦ä¸²
    @return: OpenCVå›¾åƒæ•°ç»„
    """
    try:
        # è§£ç Base64æ•°æ®
        if ',' in base64_image:
            image_data = base64.b64decode(base64_image.split(',')[1])
        else:
            image_data = base64.b64decode(base64_image)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        np_array = np.frombuffer(image_data, np.uint8)
        
        # è§£ç ä¸ºOpenCVå›¾åƒ
        opencv_image = cv2.imdecode(np_array, cv2.IMREAD_COLOR)
        
        if opencv_image is None:
            raise ValueError("å›¾åƒè§£ç å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ— æ•ˆçš„å›¾åƒæ ¼å¼")
        
        return opencv_image
        
    except Exception as e:
        logger.error(f"å›¾åƒæ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
        raise

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'healthy',
        'service': 'EmotiSync API',
        'version': '1.0.0',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/inference', methods=['POST', 'OPTIONS'])
def emotion_recognition_api():
    """è¡¨æƒ…è¯†åˆ«ä¸»æ¥å£"""
    
    if request.method == 'OPTIONS':
        # å¤„ç†é¢„æ£€è¯·æ±‚
        return '', 200
    
    start_time = datetime.now()
    
    try:
        # éªŒè¯è¯·æ±‚æ•°æ®
        request_data = request.get_json()
        if not request_data:
            return jsonify({
                'success': False,
                'error': 'è¯·æ±‚æ•°æ®ä¸ºç©º',
                'code': 'INVALID_REQUEST'
            }), 400
        
        if 'image' not in request_data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å›¾åƒæ•°æ®',
                'code': 'MISSING_IMAGE'
            }), 400
        
        logger.info("å¼€å§‹å¤„ç†è¡¨æƒ…è¯†åˆ«è¯·æ±‚")
        
        # å¤„ç†å›¾åƒæ•°æ®
        input_image = process_image_data(request_data['image'])
        
        # äººè„¸æ£€æµ‹
        annotated_image, face_crops, face_positions = detect_faces_in_image(input_image)
        
        # è¡¨æƒ…åˆ†ç±»ç»“æœ
        recognition_results = []
        
        if face_crops:
            for idx, face_crop in enumerate(face_crops):
                emotion_label, confidence = classify_facial_expression(face_crop)
                
                # åœ¨å›¾åƒä¸Šæ ‡æ³¨è¡¨æƒ…ç»“æœ
                x1, y1, x2, y2 = face_positions[idx]
                cv2.putText(
                    annotated_image, 
                    f"{emotion_label}", 
                    (x1, y1 - 15), 
                    cv2.FONT_HERSHEY_SIMPLEX, 
                    0.8, 
                    (46, 204, 113), 2
                )
                
                # è®°å½•ç»“æœ
                recognition_results.append({
                    'box': face_positions[idx],
                    'expression': emotion_label,
                    'confidence': round(confidence, 4)
                })
        
        # ç¼–ç å¤„ç†åçš„å›¾åƒ
        encode_success, image_buffer = cv2.imencode('.jpg', annotated_image)
        if not encode_success:
            raise RuntimeError("å›¾åƒç¼–ç å¤±è´¥")
        
        result_image_b64 = base64.b64encode(image_buffer).decode('utf-8')
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # æ„å»ºå“åº”
        response = {
            'success': True,
            'faces': recognition_results,
            'total_faces': len(recognition_results),
            'image': f"data:image/jpeg;base64,{result_image_b64}",
            'processing_time': round(processing_time, 3),
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"è¡¨æƒ…è¯†åˆ«å®Œæˆï¼Œæ£€æµ‹åˆ°{len(recognition_results)}å¼ äººè„¸ï¼Œè€—æ—¶{processing_time:.3f}ç§’")
        
        # æ·»åŠ CORSå¤´éƒ¨ç¡®ä¿è·¨åŸŸå…¼å®¹
        response_obj = jsonify(response)
        response_obj.headers.add('Access-Control-Allow-Origin', '*')
        response_obj.headers.add('Access-Control-Allow-Methods', 'POST, OPTIONS')
        response_obj.headers.add('Access-Control-Allow-Headers', 'Content-Type')
        
        return response_obj
        
    except Exception as e:
        error_msg = f"è¡¨æƒ…è¯†åˆ«å¤„ç†å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        
        return jsonify({
            'success': False,
            'error': error_msg,
            'code': 'PROCESSING_ERROR',
            'timestamp': datetime.now().isoformat()
        }), 500

@app.errorhandler(413)
def file_too_large(e):
    """æ–‡ä»¶å¤§å°è¶…é™å¤„ç†"""
    return jsonify({
        'success': False,
        'error': 'ä¸Šä¼ æ–‡ä»¶è¿‡å¤§ï¼Œè¯·é€‰æ‹©å°äº16MBçš„æ–‡ä»¶',
        'code': 'FILE_TOO_LARGE'
    }), 413

@app.errorhandler(500)
def internal_error(e):
    """å†…éƒ¨æœåŠ¡å™¨é”™è¯¯å¤„ç†"""
    return jsonify({
        'success': False,
        'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯',
        'code': 'INTERNAL_ERROR'
    }), 500

def get_local_ip():
    """è·å–æœ¬æœºIPåœ°å€"""
    import socket
    try:
        # åˆ›å»ºUDP socketè¿æ¥åˆ°å¤–éƒ¨åœ°å€è·å–æœ¬æœºIP
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(('8.8.8.8', 80))
        local_ip = s.getsockname()[0]
        s.close()
        return local_ip
    except Exception:
        return '127.0.0.1'

if __name__ == '__main__':
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        initialize_models()
        
        # è‡ªåŠ¨è·å–æœ¬æœºIPåœ°å€
        local_ip = get_local_ip()
        SERVER_HOST = '0.0.0.0'  # ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£
        SERVER_PORT = 5000
        
        # å¯åŠ¨æœåŠ¡
        logger.info(f"æŸ¥ç ”é˜…è‰²è¡¨æƒ…è¯†åˆ«æœåŠ¡å¯åŠ¨ä¸­...")
        logger.info(f"æœ¬æœºIPåœ°å€: {local_ip}")
        logger.info(f"æœåŠ¡ç›‘å¬: {SERVER_HOST}:{SERVER_PORT} (æ‰€æœ‰ç½‘ç»œæ¥å£)")
        logger.info(f"")
        logger.info(f"ğŸŒ å°ç¨‹åºè¯·ä½¿ç”¨ä»¥ä¸‹åœ°å€:")
        logger.info(f"   APIåŸºåœ°å€: http://{local_ip}:{SERVER_PORT}")
        logger.info(f"   è¡¨æƒ…è¯†åˆ«: http://{local_ip}:{SERVER_PORT}/inference")
        logger.info(f"   å¥åº·æ£€æŸ¥: http://{local_ip}:{SERVER_PORT}/health")
        logger.info(f"")
        logger.info(f"ğŸ“± è¯·å°†å°ç¨‹åºä¸­çš„SERVER_CONFIG.baseUrlä¿®æ”¹ä¸º: http://{local_ip}:{SERVER_PORT}")
        
        app.run(
            host=SERVER_HOST,
            port=SERVER_PORT,
            debug=False,
            threaded=True,
            use_reloader=False
        )
    except Exception as e:
        logger.error(f"æœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")
        exit(1)
